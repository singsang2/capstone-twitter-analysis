{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Product/Service Monitoring System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was inspired `sentdex`. (https://github.com/Sentdex/socialsentiment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is in this repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:54:55.951459Z",
     "start_time": "2020-12-08T16:54:55.946576Z"
    }
   },
   "source": [
    "**Jupyter Notebooks**\n",
    "- `product_service_monitoring_system.ipynb`: contains training and comparing of various models including BERT, TextBlob, and VADER models.\n",
    "\n",
    "**Python Files**\n",
    "- `twitter_stream.py`: connects to Twitter API and streamline tweets with various keywords\n",
    "- `app.py`: Dash dashboard\n",
    "\n",
    "**Folders**\n",
    "- `images`: contains image files\n",
    "- `models`: contains (1) BERT NLP and (2) spaCy TF-IF vectorization sentiment analysis models *(*BERT model excluded)*\n",
    "- `data`: contains SQLite3 databases pulled from Twitter using Tweepy *(only sample database is included)*\n",
    "- `datasets`: contains datasets that were used to train various NLP sentiment analysis models\n",
    "- `src`: contains useful codes that were used in creating models\n",
    "- `keys`: contains Twitter API key information *(*files excluded)*\n",
    "\n",
    "**How to use this project**\n",
    "\n",
    "1. Add Twitter API information in `keys` directory, and make sure the PATH is correctly defined in `twitter_stream.py`.\n",
    "2. Adjust any keywords or queries in `twitter_stream.py`.\n",
    "3. Set up SQLITE3 database path and run `twitter_stream.py`.\n",
    "4. Run `app.py`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Case\n",
    "As of January of 2020, there are approximately 145 million users on Twitter. 22% of Americans are on Twitter and 500 million tweets are sent each day globally. This is why many companies internationally use Twitter for marketing. In fact 80% of Twitter users have mentioned a brand in a tweet, and 77% of Twitter users feel more positive when their tweets have been replied by the mentioned brand [1].\n",
    "\n",
    "We believe that Twitter is one of the platforms that provides people to share their opinion, evaluations, attitudes, and emotions about virtually anything including certain products freely, and for any companies, this is like a gold mine waiting to be mined for `opinions are central to almost all human activities and are key influencers of our behaviors` [2].\n",
    "Sources:\n",
    "\n",
    "[1] https://unsplash.com/photos/ulRlAm1ITMU\n",
    "\n",
    "[2]. Bing Liu, https://www.morganclaypool.com/doi/abs/10.2200/s00416ed1v01y201204hlt016\n",
    "\n",
    "## Goals\n",
    "The goals of this project are to \n",
    "\n",
    "    [1] stream Twitter with on various topics (ex. Microsoft, Starbucks, Google, etc.) and\n",
    "    [2] effectively implement various NLP models (including TextBlob, BERT, and TF-IDF models) to classify tweets\n",
    "    [3] to flag the user for any strongly negative tweets on a Dashboard to effectively respond to them.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T01:12:16.170653Z",
     "start_time": "2020-12-12T01:12:16.168275Z"
    }
   },
   "source": [
    "## Models Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-12T00:21:33.626Z"
    }
   },
   "source": [
    "<img src='images/model_comparison.png' width='500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT model has accuracy of 84%, however due to its computing time, VADER was used as an initial model to classify polarity of each tweet. The BERT model was used to confirm any strongly negative sentiment tweets classified by VADER.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/dashboard_1.png'>\n",
    "\n",
    "**Keyword**\n",
    "You are able to select up to two keywords to monitor online. If you choose to choose two keywords, you **must** separate them by a comma!\n",
    "\n",
    "*if no keyword is selected, then it streams \n",
    "\n",
    "**Graph1**\n",
    "This graph represents moving average value of sentiments towards the keywords you have selected along with number of tweets sent.\n",
    "\n",
    "**Graph2**\n",
    "This pie graph represents sentiment distribution towards your keyword.\n",
    "\n",
    "<img src='images/dashboard_2.png'>\n",
    "\n",
    "By clicking `Generate Word Cloud`, it generates frequently used words in tweets related to the keywords for each sentiment. \n",
    "\n",
    "<img src='images/dashboard_3.png'>\n",
    "\n",
    "**Table1**\n",
    "This table shows recent tweets sent filtered by the keywords chosen. You are able to click on `link` button to access the actual tweet.\n",
    "\n",
    "**Table2**\n",
    "This table shows recent flagged tweets that are strongly negative.\n",
    "\n",
    "**Saving data into .csv file**\n",
    "You **must** click `GENERATE CSV FILE` before you can download the files. You can either download the whole raw tweet data or just the flagged ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Currently working on deploying the app through Heroku!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Database structure\n",
    "    - As the database size increases, it might get too much for sqlite3 to handle. So, we want to separate database into parts so only when a large number of data is requested, we can combine or join smaller databases. \n",
    "2. Reply feature\n",
    "    - It would be nice if we could add a feature where you could reply to any of tweets shown in the dashboard without going to twitter page.\n",
    "3. Multiple keywords\n",
    "    - It would be nice if multiple keywords can be analyzed and followed at a given time.\n",
    "4. Table Editing Mode\n",
    "    - Modify flagged tweets in the dashboard so that a user can classify flagged tweets as 'resolved', 'false negative', or 'other' for further customer service / data analysis.\n",
    "5. Further analysis on both positive and negative tweets\n",
    "    - Find any correlation between tweet trends with how the company is doing to help with future direction of a company."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
